import os
import shutil
import streamlit as st

from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.chat_models import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda

# -------------------------------
# í™˜ê²½ ì„¤ì •
# -------------------------------
load_dotenv(".env")

VECTORSTORE_DIR = "faiss_index"
MAX_DOCS = 5  # ìµœëŒ€ ì²¨ë¶€ ê°€ëŠ¥ ë¬¸ì„œ ìˆ˜


# -------------------------------
# ìœ í‹¸ í•¨ìˆ˜ë“¤
# -------------------------------
def load_and_split_docs(uploaded_file):
    """
    ì—…ë¡œë“œëœ PDF/TXTë¥¼ ë¡œì»¬ì— ì €ì¥ í›„ LangChain Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ ,
    RecursiveCharacterTextSplitterë¡œ chunk ë‹¨ìœ„ë¡œ ë¶„í• í•œë‹¤.
    """
    with open(uploaded_file.name, "wb") as f:
        f.write(uploaded_file.getbuffer())

    if uploaded_file.name.endswith(".pdf"):
        loader = PyPDFLoader(uploaded_file.name)
    else:
        loader = TextLoader(uploaded_file.name, encoding="utf-8")

    documents = loader.load()

    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    docs = splitter.split_documents(documents)

    # ê° chunkì— source(íŒŒì¼ëª…) ë©”íƒ€ë°ì´í„° ì§€ì •
    for d in docs:
        d.metadata["source"] = uploaded_file.name

    return docs


def create_vectorstore(docs):
    """
    ì£¼ì–´ì§„ ë¬¸ì„œë“¤ë¡œ ìƒˆ FAISS ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ê³  ë¡œì»¬ì— ì €ì¥í•œë‹¤.
    (ì´ì „ ì¸ë±ìŠ¤ëŠ” ë°–ì—ì„œ ì´ë¯¸ ì‚­ì œí–ˆë‹¤ê³  ê°€ì •)
    """
    embeddings = OpenAIEmbeddings()
    vectordb = FAISS.from_documents(docs, embeddings)
    vectordb.save_local(VECTORSTORE_DIR)
    return vectordb


def build_rag_chain(vectordb, task_mode: str, active_sources):
    """
    ê³¼ì œ/ë ˆí¬íŠ¸ ë„ìš°ë¯¸ìš© RAG ì²´ì¸.
    active_sources: ì‚¬ìš©í•  ë¬¸ì„œ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì „ì²´)
    task_mode:
      - "ë¬¸ì„œ ìš”ì•½" / "ë ˆí¬íŠ¸ ëª©ì°¨ ì„¤ê³„" / "í•µì‹¬ ë‚´ìš© ì •ë¦¬" / "ì˜ˆìƒ ì‹œí—˜ë¬¸ì œ ìƒì„±"
    """
    base_instruction = """
    ë„ˆëŠ” ì—…ë¡œë“œëœ ë¬¸ì„œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ê³¼ì œì™€ ë ˆí¬íŠ¸ ì‘ì„±ì„ ë„ì™€ì£¼ëŠ” AI ì¡°êµì•¼.
    í•­ìƒ ë¬¸ì„œ ë‚´ìš©ì„ ìµœìš°ì„ ìœ¼ë¡œ ì°¸ê³ í•´ì„œ ë‹µí•´ì•¼ í•˜ê³ ,
    ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì´ë¼ ì¼ë°˜ì ì¸ ì„¤ëª…ì„ í• ê²Œ."ë¼ê³  ë¨¼ì € ì•Œë ¤ì¤€ ë’¤ ì„¤ëª…í•´.
    """

    if task_mode == "ë¬¸ì„œ ìš”ì•½":
        task_instruction = """
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì§€ì •í•œ ë²”ìœ„ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¬¸ì„œ ë‚´ìš©ì„ 3~7ë¬¸ì¥ ì •ë„ë¡œ ìš”ì•½í•´ì¤˜.
        ì¤‘ìš” ê°œë…, í•µì‹¬ ì£¼ì¥, ê²°ë¡ ì´ ë¹ ì§€ì§€ ì•Šê²Œ ì •ë¦¬í•´.
        """
    elif task_mode == "ë ˆí¬íŠ¸ ëª©ì°¨ ì„¤ê³„":
        task_instruction = """
        ì´ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ A4 3~5ì¥ ë¶„ëŸ‰ì˜ ë ˆí¬íŠ¸ ëª©ì°¨ë¥¼ ì„¤ê³„í•´ì¤˜.
        1, 1-1, 1-2 ì™€ ê°™ì€ ê³„ì¸µ êµ¬ì¡°ë¡œ ì‘ì„±í•˜ê³ ,
        ê° ì†Œì œëª© ì˜†ì— í•œ ì¤„ì”© ê·¸ ë¶€ë¶„ì— ì“°ë©´ ì¢‹ì„ ë‚´ìš©ì„ ì„¤ëª…í•´ì¤˜.
        """
    elif task_mode == "í•µì‹¬ ë‚´ìš© ì •ë¦¬":
        task_instruction = """
        ì´ ë¬¸ì„œì—ì„œ ì‚¬ìš©ìê°€ ê¶ê¸ˆí•´í•˜ëŠ” ì£¼ì œì™€ ê´€ë ¨ëœ í•µì‹¬ ê°œë…, ì£¼ì¥, ê·¼ê±°ë¥¼
        bullet ëª©ë¡ í˜•íƒœë¡œ ì§§ê³  ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ì¤˜.
        """
    elif task_mode == "ì˜ˆìƒ ì‹œí—˜ë¬¸ì œ ìƒì„±":
        task_instruction = """
        ì´ ë¬¸ì„œë¥¼ ê³µë¶€í•˜ëŠ” í•™ìƒì—ê²Œ ì‹œí—˜ì´ë‚˜ êµ¬ë‘ ë°œí‘œì—ì„œ ë‚˜ì˜¬ ë²•í•œ ë¬¸ì œë¥¼ 3~5ê°œ ë§Œë“¤ì–´ì¤˜.
        ì„œìˆ í˜•, ê°ê´€ì‹, ë…¼ìˆ í˜• ë“±ì„ ì„ì–´ë„ ì¢‹ê³ ,
        ê° ë¬¸ì œë§ˆë‹¤ ëª¨ë²”ë‹µì•ˆì˜ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ 2~3ì¤„ ì •ë„ë¡œ ì œì‹œí•´ì¤˜.
        """
    else:  # "ììœ  ì§ˆì˜ì‘ë‹µ" ë“±
        task_instruction = """
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ë‹µí•˜ë˜,
        ë°˜ë“œì‹œ ë¬¸ì„œì—ì„œ ê·¼ê±°ê°€ ë˜ëŠ” ë‚´ìš© ìœ„ì£¼ë¡œ ì„¤ëª…í•´ì¤˜.
        """

    prompt = ChatPromptTemplate.from_template(
        base_instruction
        + """
        [ëŒ€í™” íˆìŠ¤í† ë¦¬]
        {history}

        [ì‘ì—… ì§€ì¹¨]
        """
        + task_instruction
        + """
        
        [ì‚¬ìš©ì ì§ˆë¬¸]
        {question}

        [ì°¸ê³  ë¬¸ì„œ ë‚´ìš©]
        {context}
        """
    )

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.5)

    def get_context_from_sources(inputs):
        question = inputs["question"]
        docs = vectordb.similarity_search(question, k=12)

        # active_sourcesê°€ ì§€ì •ë˜ë©´ í•´ë‹¹ sourceë§Œ í•„í„°ë§
        if active_sources:
            docs = [d for d in docs if d.metadata.get("source") in active_sources]

        if not docs:
            return "ì„ íƒí•œ ë¬¸ì„œë“¤ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        return "\n\n".join([d.page_content for d in docs])

    rag_chain = (
        {
            "context": RunnableLambda(get_context_from_sources),
            "question": RunnableLambda(lambda x: x["question"]),
            "history": RunnableLambda(lambda x: x.get("history", "")),
        }
        | prompt
        | llm
    )
    return rag_chain


# ëŒ€í™”ë‚´ìš© ìš”ì•½ìš©
def build_history_text():
    # ìµœê·¼ 6~8ê°œ ì •ë„ë§Œ ì‚¬ìš© (ë„ˆë¬´ ê¸¸ë©´ í”„ë¡¬í”„íŠ¸ í­ë°œ)
    msgs = st.session_state.chat_messages[-8:]

    lines = []
    for m in msgs:
        role = "ì‚¬ìš©ì" if m["role"] == "user" else "AI"
        lines.append(f"{role}: {m['content']}")
    return "\n".join(lines)


# -------------------------------
# Streamlit UI
# -------------------------------
st.set_page_config(
    page_title="ê³¼ì œ ë„ìš°ë¯¸ ì±—ë´‡",
    page_icon="ğŸ“š",
    layout="wide",
)

# -------------------------------
# ê¸€ë¡œë²Œ ìŠ¤íƒ€ì¼ (ë°ê³  ì„¸ë ¨ëœ ì»¨ì…‰)
# -------------------------------
custom_css = """
<style>
/* ì „ì²´ ë°°ê²½ & ë©”ì¸ ì˜ì—­ */
[data-testid="stAppViewContainer"] > .main {
    background: radial-gradient(circle at top left, #fef6ff 0, #f5f8ff 35%, #f6fbff 70%, #ffffff 100%);
}

[data-testid="stHeader"] {
    background: rgba(255, 255, 255, 0.0);
}

/* ê¸°ë³¸ ì»¨í…Œì´ë„ˆ ì—¬ë°± */
.block-container {
    padding-top: 2rem;
    padding-bottom: 3rem;
}

/* ì„¹ì…˜ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
.app-card {
    padding: 1.4rem 1.6rem;
    border-radius: 1.2rem;
    background: rgba(255, 255, 255, 0.85);
    border: 1px solid rgba(180, 196, 255, 0.35);
    box-shadow: 0 12px 30px rgba(15, 23, 42, 0.04);
}

/* === ê²°ê³¼ í—¤ë”ìš© ì»´íŒ©íŠ¸ ì¹´ë“œ === */
.result-header-card {
    display: inline-block;           /* ì „ì²´ ê°€ë¡œí­ ë‹¤ ì“°ì§€ ì•Šê³  í…ìŠ¤íŠ¸ë§Œ ê°ì‹¸ê²Œ */
    padding: 0.25rem 0.55rem;         /* ì„¸ë¡œ/ê°€ë¡œ íŒ¨ë”© ì¤„ì´ê¸° */
    border-radius: 0.8rem;
    background: rgba(255, 255, 255, 0.95);
    border: 1px solid rgba(180, 196, 255, 0.7);
    box-shadow: 0 6px 18px rgba(15, 23, 42, 0.04);
    margin-bottom: 0.4rem;
}

.result-header-card h4 {
    margin: 0;
    font-size: 0.98rem;
    font-weight: 700;
}

/* ì œëª© ì˜ì—­ */
.app-hero {
    padding: 1.8rem 1.8rem 1.4rem 1.8rem;
    border-radius: 1.4rem;
    background: linear-gradient(135deg, #eef2ff 0%, #fdf2ff 50%, #ffffff 100%);
    border: 1px solid rgba(180, 196, 255, 0.5);
    box-shadow: 0 18px 40px rgba(15, 23, 42, 0.06);
}

.app-hero-title {
    font-size: 1.9rem;
    font-weight: 800;
    letter-spacing: -0.03em;
    margin-bottom: 0.4rem;
}

.app-hero-subtitle {
    font-size: 0.98rem;
    color: #4b5563;
}

/* ì‘ì€ ë±ƒì§€ */
.app-badge {
    display: inline-flex;
    align-items: center;
    gap: 0.25rem;
    padding: 0.18rem 0.7rem;
    border-radius: 999px;
    background: rgba(99, 102, 241, 0.06);
    color: #4f46e5;
    font-size: 0.75rem;
    font-weight: 600;
}

/* ë‹¨ê³„ ì•ˆë‚´ ë¦¬ìŠ¤íŠ¸ */
.app-steps {
    font-size: 0.92rem;
    color: #4b5563;
}

.app-steps li {
    margin-bottom: 0.25rem;
}

/* ì„œë¸Œí—¤ë” ì •ë¦¬ */
h3 {
    margin-top: 1.6rem !important;
    margin-bottom: 0.6rem !important;
}

/* ë¼ë””ì˜¤/ì…€ë ‰íŠ¸ ë“± ìœ„ì ¯ ì—¬ë°± */
[data-testid="stRadio"], [data-testid="stSelectbox"] {
    padding: 0.4rem 0.6rem;
    border-radius: 0.9rem;
    background: rgba(248, 250, 252, 0.85);
}

/* ë²„íŠ¼ & ê²½ê³ /ì •ë³´ ë°•ìŠ¤ í†¤ ë§ì¶”ê¸° */
.stButton button {
    border-radius: 999px;
    font-weight: 600;
}

.stAlert {
    border-radius: 0.9rem;
}

/* ì±„íŒ… ë²„ë¸” ëŠë‚Œ ì‚´ì§ */
[data-testid="stChatMessage"] {
    border-radius: 1rem;
    padding: 0.4rem 0.6rem;
    background: rgba(255, 255, 255, 0.7);
    border: 1px solid rgba(226, 232, 240, 0.7);
}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# -------------------------------
# ìƒë‹¨ íˆì–´ë¡œ ì˜ì—­
# -------------------------------
st.markdown(
    """
    <div class="app-hero">
        <div class="app-badge">ğŸ“š ê³¼ì œÂ·ë ˆí¬íŠ¸ ì „ìš© Â· RAG ì±—ë´‡</div>
        <div class="app-hero-title">ê³¼ì œ ë„ìš°ë¯¸ ì±—ë´‡</div>
        <div class="app-hero-subtitle">
            PDF Â· TXTë¥¼ ì—…ë¡œë“œí•˜ë©´, ìš”ì•½ë¶€í„° ë ˆí¬íŠ¸ ëª©ì°¨, í•µì‹¬ ì •ë¦¬, ì˜ˆìƒ ì‹œí—˜ë¬¸ì œê¹Œì§€<br/>
            ë¬¸ì„œ ë‚´ìš©ì„ í† ëŒ€ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë„ì™€ì£¼ëŠ” AI ì¡°êµì…ë‹ˆë‹¤.
        </div>
    </div>
    """,
    unsafe_allow_html=True,
)

st.markdown("")
st.markdown(
    """
<div class="app-card">
<strong>ì´ë ‡ê²Œ í™œìš©í•´ ë³´ì„¸ìš”.</strong>

<ul class="app-steps">
<li><b>1ë‹¨ê³„ Â· ë¬¸ì„œ ì—…ë¡œë“œ</b> â€“ ê°•ì˜ë¡, êµì¬ PDF, ë…¼ë¬¸, ë³´ê³ ì„œ ì´ˆì•ˆ ë“± ìµœëŒ€ 5ê°œê¹Œì§€ ì˜¬ë¦½ë‹ˆë‹¤.</li>
<li><b>2ë‹¨ê³„ Â· ì‘ì—… ëª¨ë“œ ì„ íƒ</b> â€“ ìš”ì•½, ë ˆí¬íŠ¸ ëª©ì°¨ ì„¤ê³„, í•µì‹¬ ë‚´ìš© ì •ë¦¬, ì˜ˆìƒ ì‹œí—˜ë¬¸ì œ ìƒì„± ì¤‘ ì„ íƒí•˜ê±°ë‚˜, ììœ  ëŒ€í™” ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.</li>
<li><b>3ë‹¨ê³„ Â· ì§ˆë¬¸ ë˜ëŠ” ìë™ ì‹¤í–‰</b> â€“ ì„ íƒí•œ ëª¨ë“œì— ë§ê²Œ ì§ˆë¬¸í•˜ë©´, ë¬¸ì„œ ë‚´ìš©ì„ ìš°ì„ ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.</li>
</ul>
</div>
""",
    unsafe_allow_html=True,
)

# -------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -------------------------------
if "vectordb" not in st.session_state:
    st.session_state.vectordb = None
if "sources" not in st.session_state:
    st.session_state.sources = []  # ì´ë²ˆ ì„¸ì…˜ì—ì„œ ì—…ë¡œë“œí•œ ë¬¸ì„œ ì´ë¦„ë“¤
if "rag_chain" not in st.session_state:
    st.session_state.rag_chain = None
if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []  # ëŒ€í™”í˜• ëª¨ë“œìš© ë©”ì‹œì§€ ê¸°ë¡
if "prev_mode" not in st.session_state:
    st.session_state.prev_mode = None
if "last_task_mode" not in st.session_state:
    st.session_state.last_task_mode = None
if "last_task_result" not in st.session_state:
    st.session_state.last_task_result = None

# -------------------------------
# 1ï¸âƒ£ ë¬¸ì„œ ì—…ë¡œë“œ
# -------------------------------
st.markdown("### 1ï¸âƒ£ ë¬¸ì„œ ì—…ë¡œë“œ")
st.caption("PDF ë˜ëŠ” TXT í˜•ì‹ì˜ í•™ìŠµìë£Œ, êµì¬, ë…¼ë¬¸ ë“±ì„ ìµœëŒ€ 5ê°œê¹Œì§€ ì˜¬ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

uploaded_files = st.file_uploader(
    "ğŸ“‚ ì—…ë¡œë“œí•  ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš” (ë“œë˜ê·¸ ì•¤ ë“œë¡­ ê°€ëŠ¥)",
    type=["pdf", "txt"],
    accept_multiple_files=True,
)

if uploaded_files:
    new_sources = [f.name for f in uploaded_files]

    if len(new_sources) > MAX_DOCS:
        st.error(
            f"í•œ ë²ˆì— ì—…ë¡œë“œí•  ìˆ˜ ìˆëŠ” ë¬¸ì„œëŠ” ìµœëŒ€ {MAX_DOCS}ê°œì…ë‹ˆë‹¤. "
            f"í˜„ì¬ ì—…ë¡œë“œ ì‹œë„ ë¬¸ì„œ ìˆ˜: {len(new_sources)}ê°œ"
        )
    else:
        # ì´ì „ ì¸ë±ìŠ¤ ì™„ì „íˆ ì œê±°
        if os.path.exists(VECTORSTORE_DIR):
            shutil.rmtree(VECTORSTORE_DIR, ignore_errors=True)

        all_docs = []
        for uf in uploaded_files:
            all_docs.extend(load_and_split_docs(uf))

        st.session_state.vectordb = create_vectorstore(all_docs)
        st.session_state.sources = new_sources

        # ê¸°ì¡´ ì‘ì—… ê²°ê³¼/ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.last_task_mode = None
        st.session_state.last_task_result = None

        st.success(f"âœ… ë¬¸ì„œ {len(new_sources)}ê°œë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ì´ì œ ì•„ë˜ì—ì„œ ì‘ì—… ëª¨ë“œë¥¼ ì„ íƒí•´ ë³´ì„¸ìš”.")

# í˜„ì¬ ì„¸ì…˜ì—ì„œ ì‚¬ìš©í•  source ëª©ë¡
active_sources = st.session_state.sources if st.session_state.sources else []

# -------------------------------
# 2ï¸âƒ£ ì‘ì—… ëª¨ë“œ ì„ íƒ
# -------------------------------
st.markdown("### 2ï¸âƒ£ ì‘ì—… ëª¨ë“œ ì„ íƒ")
st.caption("ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì±—ë´‡ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. â€¢ í…œí”Œë¦¿ ê¸°ë°˜ ìë™ ì‹¤í–‰ ë˜ëŠ” â€¢ ììœ  ëŒ€í™”í˜• ëª¨ë“œ")

mode = st.radio(
    "ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.",
    ("ğŸ§© ì‘ì—… í…œí”Œë¦¿ìœ¼ë¡œ ë°”ë¡œ ë§Œë“¤ê¸°", "ğŸ’¬ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ììœ ë¡­ê²Œ ëŒ€í™”í•˜ê¸°"),
    index=0,
)

is_template_mode = mode.startswith("ğŸ§©")

# ëª¨ë“œê°€ ë³€ê²½ë˜ë©´(íŠ¹íˆ ëŒ€í™”í˜• ëª¨ë“œë¡œ ë“¤ì–´ì˜¬ ë•Œ) ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if st.session_state.prev_mode != mode:
    if mode.startswith("ğŸ’¬"):
        st.session_state.chat_messages = []
    st.session_state.prev_mode = mode

# -------------------------------
# RAG ì²´ì¸ êµ¬ì„± (ë¬¸ì„œ+ëª¨ë“œ ê¸°ë°˜)
# -------------------------------
task_mode = None

if st.session_state.vectordb is not None and active_sources:
    if is_template_mode:
        task_mode = st.selectbox(
            "ë„ì›€ ë°›ê³  ì‹¶ì€ ì‘ì—… ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”.",
            ["ì„ íƒ ì•ˆí•¨", "ë¬¸ì„œ ìš”ì•½", "ë ˆí¬íŠ¸ ëª©ì°¨ ì„¤ê³„", "í•µì‹¬ ë‚´ìš© ì •ë¦¬", "ì˜ˆìƒ ì‹œí—˜ë¬¸ì œ ìƒì„±"],
            index=0,
        )
    else:
        # ëŒ€í™”í˜• ëª¨ë“œ: ë‚´ë¶€ì ìœ¼ë¡œ 'ììœ  ì§ˆì˜ì‘ë‹µ'
        task_mode = "ììœ  ì§ˆì˜ì‘ë‹µ"

    # ì‘ì—… ëª¨ë“œê°€ 'ì„ íƒ ì•ˆí•¨'ì´ë©´ RAG ì²´ì¸ì„ ì•„ì˜ˆ ë§Œë“¤ì§€ ì•ŠìŒ
    if task_mode != "ì„ íƒ ì•ˆí•¨":
        st.session_state.rag_chain = build_rag_chain(
            st.session_state.vectordb, task_mode, active_sources
        )
    else:
        st.session_state.rag_chain = None
else:
    st.session_state.rag_chain = None

# -------------------------------
# 3ï¸âƒ£ ëª¨ë“œë³„ ë™ì‘ ì˜ì—­
# -------------------------------
#st.markdown("### 3ï¸âƒ£ ê²°ê³¼ ë³´ê¸° ë° ëŒ€í™”")

if is_template_mode:
    # ëª¨ë“œ 1: ì‘ì—… í…œí”Œë¦¿ ëª¨ë“œ (ë“œë¡­ë‹¤ìš´ ì„ íƒ ì‹œ ìë™ ì‹¤í–‰)

    if st.session_state.vectordb is None or not active_sources:
        st.info("ë¨¼ì € ìœ„ì—ì„œ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ì‘ì—… í…œí”Œë¦¿ ëª¨ë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        if task_mode == "ì„ íƒ ì•ˆí•¨":
            # ì‘ì—… ëª¨ë“œë¥¼ ì„ íƒí•˜ì§€ ì•Šì€ ê²½ìš°: ê²°ê³¼ ì¶œë ¥ X, ì•ˆë‚´ë§Œ
            st.session_state.last_task_mode = None
            st.session_state.last_task_result = None
            st.info("ìœ„ ì…€ë ‰íŠ¸ ë°•ìŠ¤ì—ì„œ ì›í•˜ëŠ” ì‘ì—… ìœ í˜•ì„ ì„ íƒí•˜ë©´, í•´ë‹¹ ì‘ì—…ì´ ìë™ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        elif st.session_state.rag_chain and task_mode is not None:
            # ì‘ì—… ìœ í˜•ì— ë”°ë¼ ìë™ ì§ˆë¬¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            if task_mode == "ë¬¸ì„œ ìš”ì•½":
                auto_question = "ì´ ë¬¸ì„œ ì „ì²´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•µì‹¬ ë‚´ìš©ì„ 3~7ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜."
            elif task_mode == "ë ˆí¬íŠ¸ ëª©ì°¨ ì„¤ê³„":
                auto_question = "ì´ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ A4 3~5ì¥ ë¶„ëŸ‰ì˜ ë ˆí¬íŠ¸ ëª©ì°¨ë¥¼ ì„¤ê³„í•´ì¤˜."
            elif task_mode == "í•µì‹¬ ë‚´ìš© ì •ë¦¬":
                auto_question = "ì´ ë¬¸ì„œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ê°œë…, ì£¼ì¥, ê·¼ê±°ë¥¼ ì •ë¦¬í•´ì¤˜."
            elif task_mode == "ì˜ˆìƒ ì‹œí—˜ë¬¸ì œ ìƒì„±":
                auto_question = "ì´ ë¬¸ì„œë¡œ ì‹œí—˜ì´ë‚˜ êµ¬ë‘ ë°œí‘œì—ì„œ ë‚˜ì˜¬ ë²•í•œ ë¬¸ì œë¥¼ 3~5ê°œ ë§Œë“¤ì–´ì¤˜."
            else:  # "ììœ  ì§ˆì˜ì‘ë‹µ" ë“±
                auto_question = "ì´ ë¬¸ì„œì˜ ì „ì²´ ë‚´ìš©ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í•µì‹¬ ì„¤ëª…ì„ í•´ì¤˜."

            # ì‘ì—…ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ìƒˆë¡œ ì‹¤í–‰
            if (
                task_mode != st.session_state.last_task_mode
                or st.session_state.last_task_result is None
            ):
                with st.spinner("ì„ íƒí•œ ì‘ì—…ì„ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    result = st.session_state.rag_chain.invoke({"question": auto_question})
                    st.session_state.last_task_result = result.content
                    st.session_state.last_task_mode = task_mode

            # ê²°ê³¼ í‘œì‹œ (ì¹´ë“œ ì•ˆì— ë„£ê¸°)
            st.markdown(
                f"""
                <div class="result-header-card">
                    <h4>âœï¸ ì‘ì—… ê²°ê³¼ â€“ {task_mode}</h4>
                </div>
                """,
                unsafe_allow_html=True,
            )
            # st.markdown(
            #     f"""
            #     <div class="app-card">
            #         <h3>âœï¸ ì‘ì—… ê²°ê³¼ â€“ {task_mode}</h3>
            #     </div>
            #     """,
            #     unsafe_allow_html=True,
            # )
            st.write(st.session_state.last_task_result)
        else:
            st.info("ì‘ì—… ìœ í˜•ì„ ë‹¤ì‹œ ì„ íƒí•´ ì£¼ì„¸ìš”.")
else:
    # ëª¨ë“œ 2: ëŒ€í™”í˜• ëª¨ë“œ (ì±„íŒ…)

    # ê¸°ì¡´ ëŒ€í™” ë‚´ìš© í‘œì‹œ
    for msg in st.session_state.chat_messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì±„íŒ… ì…ë ¥ì°½
    user_msg = st.chat_input("ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì–´ë–¤ ì ì´ ê¶ê¸ˆí•œê°€ìš”? ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ì„¸ìš”.")

    if user_msg:
        # ë¬¸ì„œ/ì²´ì¸ ì¤€ë¹„ ì•ˆ ëì„ ë•Œ
        if st.session_state.rag_chain is None:
            st.warning("ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì•¼ ëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡ ë° í™”ë©´ ì¶œë ¥
            st.session_state.chat_messages.append({"role": "user", "content": user_msg})
            with st.chat_message("user"):
                st.markdown(user_msg)

            history_text = build_history_text()

            # RAG í˜¸ì¶œ
            with st.chat_message("assistant"):
                with st.spinner("ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ì •ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    result = st.session_state.rag_chain.invoke(
                        {"question": user_msg, "history": history_text}
                    )
                    answer = result.content
                    st.markdown(answer)

            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ê¸°ë¡
            st.session_state.chat_messages.append({"role": "assistant", "content": answer})
